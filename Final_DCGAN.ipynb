{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritujashinde97/DCGAN_Final_Project/blob/main/Final_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhpdLeRd4PY3",
        "outputId": "5cc5eed9-94be-4965-9bcf-f8a910d037fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow.io\n",
            "  Downloading tensorflow_io-0.28.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.28.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.28.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 43.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow.io\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.27.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.27.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.27.0\n",
            "Successfully installed tensorflow-io-gcs-filesystem-0.28.0 tensorflow.io-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac_L9WkwdmNQ",
        "outputId": "6be2fdd5-37cc-45d4-f01d-93491bfd19ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from matplotlib import pyplot\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN21MXwWef_I"
      },
      "outputs": [],
      "source": [
        "IMG_H = 64\n",
        "IMG_W = 64\n",
        "IMG_C = 3\n",
        "\n",
        "w_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UR73qPmK7fw",
        "outputId": "e3a5542d-d5fb-4593-da81-891b8347acb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6ia3SSVhLzy",
        "outputId": "f5f11924-8610-4621-dd3f-bb1b7223fbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size:  20\n"
          ]
        }
      ],
      "source": [
        "##Dataset\n",
        "images_path = glob(\"/content/drive/MyDrive/DRIVE_64/*\")\n",
        "print(\"Dataset Size: \", len(images_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBhPgspKiDJ3"
      },
      "outputs": [],
      "source": [
        "def load_image(image_path):\n",
        "  image = tf.io.read_file(image_path)\n",
        "  image = tf.io.decode_png(image)\n",
        "  #image = tfio.experimental.image.decode_tiff(image)\n",
        "  #image = tf.io.decode_tiff(image)\n",
        "  image = tf.image.resize(image,(IMG_H,IMG_W))\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image - 127.5)/127.5\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAcQof90g285",
        "outputId": "272ef730-7a74-4223-9eef-7183809bd2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  print(\"\")\n",
        "  #hyperparameters\n",
        "  batch_size = 4 #no of training examples used in one iteration\n",
        "  latent_dim = 4\n",
        "  num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gladKKmzx9JF"
      },
      "outputs": [],
      "source": [
        "def tf_dataset(images_path, batch_size):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(images_path)\n",
        "  dataset = dataset.shuffle(buffer_size = 5)\n",
        "  dataset = dataset.map(load_image, num_parallel_calls = tf.data.experimental.AUTOTUNE) #tunes the value at runtime\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
        "  return dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azywQH3_zTx6",
        "outputId": "5076b870-86b5-4dce-dc01-1e3138e1e65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 64, 64, 3)\n",
            "(4, 64, 64, 3)\n",
            "(4, 64, 64, 3)\n",
            "(4, 64, 64, 3)\n",
            "(4, 64, 64, 3)\n"
          ]
        }
      ],
      "source": [
        "dataset = tf_dataset(images_path, batch_size)\n",
        "\n",
        "for x in dataset:\n",
        "  print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tXjQH026Ahy"
      },
      "outputs": [],
      "source": [
        "#used in generator\n",
        "#deconv -> transposed convolutions \n",
        "def deconv_block(inputs, num_filters, kernel_size, strides, bn=True):\n",
        "  x = Conv2DTranspose(\n",
        "      filters = num_filters,\n",
        "      kernel_size = kernel_size, #defines field view of the convolution(2D->3*3 pixels)\n",
        "      kernel_initializer = w_init,\n",
        "      padding = \"same\", #handles border of sample\n",
        "      strides = strides, #step size while traversing the image\n",
        "      use_bias = False\n",
        "  )(inputs)\n",
        "\n",
        "  if bn : \n",
        "    x = BatchNormalization()(x)  #for training very deep neural networks that standardizes the inputs to a layer for each mini-batch\n",
        "    x = LeakyReLU(alpha=0.2)(x) #activation function\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULBjQL8ABhro"
      },
      "outputs": [],
      "source": [
        "#used in generator\n",
        "def conv_block(inputs, num_filters, kernel_size, padding=\"same\", strides=2, activation = True) :\n",
        "  x = Conv2D(\n",
        "      filters = num_filters,\n",
        "      kernel_size = kernel_size,\n",
        "      kernel_initializer = w_init,\n",
        "      padding = padding,\n",
        "      strides = strides\n",
        "  )(inputs)\n",
        "\n",
        "  if activation :\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "  \n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcx_j8nIDFZO"
      },
      "outputs": [],
      "source": [
        "#it mirrors disriminator, replacing Conv2D layers with Conv2Dtranspose\n",
        "def build_generator(latent_dim):\n",
        "  f = [2**i for i in range(5)][::-1]\n",
        "  filters = 32\n",
        "  output_strides = 16\n",
        "  h_output = IMG_H // output_strides\n",
        "  w_output = IMG_W // output_strides\n",
        "\n",
        "  noise = Input(shape=(latent_dim), name = \"gen_noise_input\")\n",
        "\n",
        "  x = Dense(f[0] * filters * h_output * w_output, use_bias = False)(noise)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  x = Reshape((h_output, w_output, f[0] * filters))(x)\n",
        "  print(x.shape)\n",
        "  for i in range(1,5):\n",
        "    x = deconv_block(x,\n",
        "              num_filters = f[i]*filters,\n",
        "              kernel_size = 5,\n",
        "              strides = 2,\n",
        "              bn = True       \n",
        "                )\n",
        "  print(x.shape)\n",
        "\n",
        "  x = conv_block(x,\n",
        "            num_filters = 3,\n",
        "            kernel_size = 5,\n",
        "            strides = 1,\n",
        "            activation = False    \n",
        "                 )\n",
        "  fake_output = Activation(\"tanh\")(x)\n",
        "\n",
        "  return Model(noise, fake_output, name = \"generator\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsYm36mLUUoJ"
      },
      "outputs": [],
      "source": [
        "def build_discriminator():\n",
        "  f = [2**i for i in range(4)]\n",
        "  filters = 64\n",
        "  output_strides = 16\n",
        "  h_output = IMG_H // output_strides\n",
        "  w_output = IMG_W // output_strides\n",
        "\n",
        "  image_input = Input(shape=(IMG_H, IMG_W, IMG_C), name = \"images\")\n",
        "  x = image_input\n",
        "\n",
        "  for i in range(0,4):\n",
        "    x = conv_block(x,\n",
        "             num_filters = f[i]*filters,\n",
        "             kernel_size = 5,\n",
        "             strides = 2,      \n",
        "                   )\n",
        "    \n",
        "    x = Flatten()(x) \n",
        "    x = Dense(1)(x)\n",
        "#Flatten layers are used when you got a multidimensional output and you want to make it linear to pass it onto a Dense layer.\n",
        "#Dense Layer is used to classify image based on output from convolutional layers.\n",
        "    return Model(image_input, x, name = \"discriminator\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMcjHO-yN7Nm",
        "outputId": "145667d8-de8a-43f1-8ad6-b64a1de1dce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 4, 4, 512)\n",
            "(None, 64, 64, 32)\n"
          ]
        }
      ],
      "source": [
        "g_model = build_generator(latent_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZwnyFyBWRIi"
      },
      "outputs": [],
      "source": [
        "d_model = build_discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyhs3WwvWV5C",
        "outputId": "d76d359f-ead8-49f4-f2cc-852d38ccc163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gen_noise_input (InputLayer  [(None, 4)]              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8192)              32768     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 8192)             32768     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 8192)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 256)        3276800   \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 128)      819200    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 64)       204800    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 32)       51200     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 64, 64, 3)         2403      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,421,859\n",
            "Trainable params: 4,404,515\n",
            "Non-trainable params: 17,344\n",
            "_________________________________________________________________\n",
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " images (InputLayer)         [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        4864      \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65537     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 70,401\n",
            "Trainable params: 70,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "g_model.summary()\n",
        "d_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHEpm3f_YiEl"
      },
      "outputs": [],
      "source": [
        "class GAN(Model) :\n",
        "  def __init__ (self, discriminator, generator, latent_dim) :\n",
        "    super(GAN, self).__init__()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def compile(self, d_optimizer,g_optimizer,loss_fn,metric):\n",
        "    super(GAN,self).compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.loss_fn = loss_fn\n",
        "    self.metric = metric\n",
        "  \n",
        "  def train_step(self, real_images):\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "    #Training Discriminator\n",
        "    for _ in range(2):\n",
        "      #Fake_images\n",
        "      random_latent_vectors = tf.random.normal(shape=(batch_size,self.latent_dim))\n",
        "      generated_images = self.generator(random_latent_vectors)\n",
        "      generated_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "      with tf.GradientTape() as ftape :\n",
        "        predictions = self.discriminator(generated_images)\n",
        "        d1_loss = self.loss_fn(generated_labels, predictions)\n",
        "        d1_acc = self.metric(generated_labels, predictions)\n",
        "\n",
        "      grads = ftape.gradient(d1_loss, self.discriminator.trainable_weights)\n",
        "      self.d_optimizer.apply_gradients(zip(grads,self.discriminator.trainable_weights))\n",
        "\n",
        "      #Real_images\n",
        "      labels = tf.ones((batch_size, 1))\n",
        "      with tf.GradientTape() as rtape :\n",
        "        predictions = self.discriminator(real_images)\n",
        "        d2_loss = self.loss_fn(labels, predictions)\n",
        "        d2_acc = self.metric(labels, predictions)\n",
        "\n",
        "      grads = rtape.gradient(d2_loss, self.discriminator.trainable_weights)\n",
        "      self.d_optimizer.apply_gradients(zip(grads,self.discriminator.trainable_weights))\n",
        "\n",
        "\n",
        "    #Training Generator\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size,self.latent_dim))\n",
        "    misleading_labels = tf.ones((batch_size, 1))\n",
        "\n",
        "    with tf.GradientTape() as gtape: \n",
        "      predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "      g_loss = self.loss_fn(misleading_labels,predictions)\n",
        "      g_acc = self.metric(misleading_labels,predictions)\n",
        "\n",
        "    grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n",
        "    self.g_optimizer.apply_gradients(zip(grads,self.generator.trainable_weights))\n",
        "\n",
        "    dict = {\"d1_loss\":d1_loss,\"d2_loss\":d2_loss,\"g_loss\":g_loss,\"d1_acc\":d1_acc,\"d2_acc\":d2_acc,\"g_acc\":g_acc}\n",
        "    \n",
        "\n",
        "    return dict;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SObCZfcYewjq"
      },
      "outputs": [],
      "source": [
        "gan = GAN(d_model, g_model, latent_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Boptkk-_Pvut"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI9H1Lxye7FZ"
      },
      "outputs": [],
      "source": [
        "bce_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits = True, label_smoothing = 0.1 ) # compares each of the predicted probabilities to actual class output which can be either 0 or 1\n",
        "d_optimizer = Adam(learning_rate=0.0002, beta_1 = 0.5)\n",
        "g_optimizer = Adam(learning_rate=0.0002, beta_1 = 0.5)\n",
        "metric = tf.keras.metrics.Accuracy()\n",
        "gan.compile(d_optimizer,g_optimizer,bce_loss_fn,metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC11w_g5V_yE"
      },
      "outputs": [],
      "source": [
        "def save_plot(examples, epoch, n):\n",
        "  examples = (examples + 1)/2.0\n",
        "  for i in range(n*n):\n",
        "    pyplot.subplot(n,n,i+1)\n",
        "    pyplot.axis(\"off\")\n",
        "    pyplot.imshow(examples[i])\n",
        "  filename = f\"/content/drive/MyDrive/sample_images_drive/fake_images_epoch_{epoch+1}.eps\"\n",
        "  pyplot.savefig(filename, format='eps')\n",
        "  pyplot.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import History \n",
        "history = History()"
      ],
      "metadata": {
        "id": "daq-XXTcfLZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqVOVXpcnAw-",
        "outputId": "26bf2fbc-23ba-42e8-99e4-db2142d72add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 6s 418ms/step - d1_loss: 0.6832 - d2_loss: 0.2420 - g_loss: 0.7080 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 2s 415ms/step - d1_loss: 0.5778 - d2_loss: 0.2055 - g_loss: 0.9055 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 2s 442ms/step - d1_loss: 0.3759 - d2_loss: 0.2312 - g_loss: 1.3100 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 2s 437ms/step - d1_loss: 0.2557 - d2_loss: 0.2153 - g_loss: 1.8652 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 2s 439ms/step - d1_loss: 0.2090 - d2_loss: 0.2054 - g_loss: 2.3842 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 2s 405ms/step - d1_loss: 0.2011 - d2_loss: 0.2023 - g_loss: 2.6372 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 2s 429ms/step - d1_loss: 0.2015 - d2_loss: 0.2319 - g_loss: 2.6346 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 2s 418ms/step - d1_loss: 0.2004 - d2_loss: 0.2099 - g_loss: 2.8288 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 2s 429ms/step - d1_loss: 0.2151 - d2_loss: 0.3129 - g_loss: 2.4197 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 2s 424ms/step - d1_loss: 0.2089 - d2_loss: 0.2473 - g_loss: 2.8902 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        }
      ],
      "source": [
        "images_dataset = tf_dataset(images_path, batch_size)\n",
        "#model fitting\n",
        "\n",
        "history = gan.fit(images_dataset, epochs = num_epochs)\n",
        "g_model.save(\"Saved Model/g_model.h5\")\n",
        "d_model.save(\"Saved Model/d_model.h5\")\n",
        "for epoch in range(num_epochs):\n",
        "  n_samples = 1\n",
        "  noise = np.random.normal(size=(n_samples, latent_dim))\n",
        "  examples = g_model.predict(noise)\n",
        "  save_plot(examples, epoch, int(np.sqrt(n_samples)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqwmdWqNnV71",
        "outputId": "aebb0dc0-8fed-45ca-ea42-6e9b9f5ad0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.callbacks.History object at 0x7f3291f60cd0>\n",
            "dict_keys(['d1_loss', 'd2_loss', 'g_loss', 'd1_acc', 'd2_acc', 'g_acc'])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(history)\n",
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Oinku_dnqVW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "32a89a2a-65c4-4478-9c78-a4a4eb77efad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "pyplot.figure(figsize=(10,5))\n",
        "pyplot.title(\"Generator and Discriminator Loss During Training\")\n",
        "pyplot.plot(history.history['g_loss'],label=\"G\")\n",
        "pyplot.plot(history.history['d1_loss'],label=\"D1\")\n",
        "pyplot.plot(history.history['d2_loss'],label=\"D2\")\n",
        "pyplot.xlabel(\"iterations\")\n",
        "pyplot.ylabel(\"Loss\")\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYpmcXSvnp8H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "J0GDmr51n0BO",
        "outputId": "a71d03ef-5d99-4628-a970-9d545f285f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 4s 320ms/step - d1_loss: 0.6734 - d2_loss: 1.1909 - g_loss: 0.6246 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "5/5 [==============================] - 2s 458ms/step - d1_loss: 0.8707 - d2_loss: 1.6653 - g_loss: 0.6460 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 60ms/step\n",
            "5/5 [==============================] - 3s 521ms/step - d1_loss: 1.1406 - d2_loss: 2.0707 - g_loss: 0.5287 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "5/5 [==============================] - 1s 289ms/step - d1_loss: 1.0941 - d2_loss: 1.4533 - g_loss: 0.5679 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "5/5 [==============================] - 1s 292ms/step - d1_loss: 0.8081 - d2_loss: 1.3405 - g_loss: 0.6651 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "4/5 [=======================>......] - ETA: 0s - d1_loss: 0.7124 - d2_loss: 1.2437 - g_loss: 0.8087 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-13dd7c56a756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved Model/g_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved Model/d_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "images_dataset = tf_dataset(images_path, batch_size)\n",
        "#model fitting\n",
        "for epoch in range(num_epochs):\n",
        "  gan.fit(images_dataset, epochs = 1)\n",
        "  g_model.save(\"Saved Model/g_model.h5\")\n",
        "  d_model.save(\"Saved Model/d_model.h5\")\n",
        "\n",
        "  n_samples = 1\n",
        "  noise = np.random.normal(size=(n_samples, latent_dim))\n",
        "  examples = g_model.predict(noise)\n",
        "  save_plot(examples, epoch, int(np.sqrt(n_samples)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zLixmKIU27M",
        "outputId": "05cda759-e178-4eb0-e337-092b4df591a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "g_model.save(\"Saved Model/g_model.h5\")\n",
        "d_model.save(\"Saved Model/d_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L868fvDMtFlv",
        "outputId": "98c7cca3-584b-4dc2-9850-666f2ecdd9e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 162ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "from matplotlib import pyplot\n",
        "\n",
        "def save_plot(examples, n):\n",
        "    examples = (examples + 1) / 2.0\n",
        "    for i in range(n * n):\n",
        "        pyplot.subplot(n, n, i+1)\n",
        "        pyplot.axis(\"off\")\n",
        "        pyplot.imshow(examples[i])\n",
        "    filename = \"fakeimage.eps\"\n",
        "    pyplot.savefig(filename, format='eps')\n",
        "    pyplot.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = load_model(\"/content/Saved Model/g_model.h5\")\n",
        "\n",
        "    n_samples = 1    ## n should always be a square of an integer.\n",
        "    latent_dim = 4\n",
        "    latent_points = np.random.normal(size=(n_samples, latent_dim))\n",
        "    examples = model.predict(latent_points)\n",
        "    save_plot(examples, int(np.sqrt(n_samples)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of calculating the frechet inception distance in Keras\n",
        "import numpy\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets.mnist import load_data\n",
        "from skimage.transform import resize\n",
        "\n",
        "fake_image_path = glob(\"/content/drive/MyDrive/sample_images_drive/*\") \n",
        "# scale an array of images to a new size\n",
        "def scale_images(fake_image_path, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in fake_image_path:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)\n",
        " \n",
        "# calculate frechet inception distance\n",
        "def calculate_fid(model, images1, images2):\n",
        "\t# calculate activations\n",
        "\tact1 = model.predict(images1)\n",
        "\tact2 = model.predict(images2)\n",
        "\t# calculate mean and covariance statistics\n",
        "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "\t# calculate sum squared difference between means\n",
        "\tssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
        "\t# calculate sqrt of product between cov\n",
        "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
        "\t# check and correct imaginary numbers from sqrt\n",
        "\tif iscomplexobj(covmean):\n",
        "\t\tcovmean = covmean.real\n",
        "\t# calculate score\n",
        "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "\treturn fid"
      ],
      "metadata": {
        "id": "EWHJXHKZhLM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyparsing import Each\n",
        "# prepare the inception v3 model\n",
        "fid_same = []\n",
        "fid_diff = []\n",
        "num_of_iterations = [5,10,15]\n",
        "for each in num_of_iterations :\n",
        "  \n",
        "  gan.fit(images_dataset, epochs = each)\n",
        "  g_model.save(\"Saved Model/g_model.h5\")\n",
        "  d_model.save(\"Saved Model/d_model.h5\")\n",
        "  for epoch in range(each) :\n",
        "    n_samples = 1\n",
        "    noise = np.random.normal(size=(n_samples, latent_dim))\n",
        "    examples = g_model.predict(noise)\n",
        "    save_plot(examples, epoch, int(np.sqrt(n_samples)))\n",
        "\n",
        "  model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
        "  # define two fake collections of images\n",
        "  images1 = randint(0, 255, 10*32*32*3)\n",
        "  images1 = images1.reshape((10,32,32,3))\n",
        "  images2 = randint(0, 255, 10*32*32*3)\n",
        "  images2 = images2.reshape((10,32,32,3))\n",
        "  print('Prepared', images1.shape, images2.shape)\n",
        "  # convert integer to floating point values\n",
        "  images1 = images1.astype('float32')\n",
        "  images2 = images2.astype('float32')\n",
        "  # resize images\n",
        "  images1 = scale_images(images1, (299,299,3))\n",
        "  images2 = scale_images(images2, (299,299,3))\n",
        "  print('Scaled', images1.shape, images2.shape)\n",
        "  # pre-process images\n",
        "  images1 = preprocess_input(images1)\n",
        "  images2 = preprocess_input(images2)\n",
        "  # fid between images1 and images1\n",
        "  fid_same.append(calculate_fid(model, images1, images1))\n",
        "  print('FID (same):', fid_same)\n",
        "  # fid between images1 and images2\n",
        "  fid_diff.append(calculate_fid(model, images1, images2))\n",
        "  print('FID (different):', fid_diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQVbCUhbhTnc",
        "outputId": "ccc7ba63-daf4-4aaf-fd41-56fbbef79e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 2s 435ms/step - d1_loss: 0.3346 - d2_loss: 0.3142 - g_loss: 1.6025 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 2s 432ms/step - d1_loss: 0.4253 - d2_loss: 0.3619 - g_loss: 1.6169 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 2s 435ms/step - d1_loss: 0.3138 - d2_loss: 0.3391 - g_loss: 1.4538 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 2s 431ms/step - d1_loss: 0.3917 - d2_loss: 0.3938 - g_loss: 1.3625 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 2s 440ms/step - d1_loss: 0.3894 - d2_loss: 0.4058 - g_loss: 1.3278 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Prepared (10, 32, 32, 3) (10, 32, 32, 3)\n",
            "Scaled (10, 299, 299, 3) (10, 299, 299, 3)\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "FID (same): [-2.2849644154288375e-05]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "FID (different): [42.51583625236779]\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 2s 403ms/step - d1_loss: 0.5435 - d2_loss: 0.4834 - g_loss: 1.2197 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 2s 398ms/step - d1_loss: 0.3299 - d2_loss: 0.4121 - g_loss: 1.3209 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 2s 410ms/step - d1_loss: 0.3434 - d2_loss: 0.4050 - g_loss: 1.4201 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 2s 416ms/step - d1_loss: 0.3897 - d2_loss: 0.4389 - g_loss: 1.4227 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 2s 399ms/step - d1_loss: 0.4478 - d2_loss: 0.5478 - g_loss: 1.3065 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 2s 400ms/step - d1_loss: 0.4361 - d2_loss: 0.5066 - g_loss: 1.1718 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 2s 394ms/step - d1_loss: 0.4449 - d2_loss: 0.5743 - g_loss: 1.0571 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 2s 393ms/step - d1_loss: 0.5124 - d2_loss: 0.6099 - g_loss: 1.0578 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 2s 413ms/step - d1_loss: 0.4812 - d2_loss: 0.5706 - g_loss: 1.0465 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 2s 407ms/step - d1_loss: 0.4551 - d2_loss: 0.5612 - g_loss: 1.0193 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "Prepared (10, 32, 32, 3) (10, 32, 32, 3)\n",
            "Scaled (10, 299, 299, 3) (10, 299, 299, 3)\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "FID (same): [-2.2849644154288375e-05, -2.8657292987432977e-05]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "FID (different): [42.51583625236779, 43.150280014234056]\n",
            "Epoch 1/15\n",
            "5/5 [==============================] - 2s 418ms/step - d1_loss: 0.4252 - d2_loss: 0.5357 - g_loss: 1.1728 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 2/15\n",
            "5/5 [==============================] - 2s 419ms/step - d1_loss: 0.4789 - d2_loss: 0.5746 - g_loss: 1.1875 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 3/15\n",
            "5/5 [==============================] - 2s 417ms/step - d1_loss: 0.4413 - d2_loss: 0.5850 - g_loss: 1.1671 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 4/15\n",
            "5/5 [==============================] - 2s 425ms/step - d1_loss: 0.5090 - d2_loss: 0.6166 - g_loss: 1.1283 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 5/15\n",
            "5/5 [==============================] - 2s 420ms/step - d1_loss: 0.5663 - d2_loss: 0.6445 - g_loss: 1.0883 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 6/15\n",
            "5/5 [==============================] - 2s 454ms/step - d1_loss: 0.5708 - d2_loss: 0.6400 - g_loss: 1.0229 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 7/15\n",
            "5/5 [==============================] - 2s 430ms/step - d1_loss: 0.5553 - d2_loss: 0.6358 - g_loss: 0.9472 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 8/15\n",
            "5/5 [==============================] - 2s 410ms/step - d1_loss: 0.5366 - d2_loss: 0.6316 - g_loss: 0.9157 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 9/15\n",
            "5/5 [==============================] - 2s 435ms/step - d1_loss: 0.5834 - d2_loss: 0.6093 - g_loss: 0.9541 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 10/15\n",
            "5/5 [==============================] - 2s 455ms/step - d1_loss: 0.4277 - d2_loss: 0.5788 - g_loss: 1.1736 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 11/15\n",
            "5/5 [==============================] - 2s 451ms/step - d1_loss: 0.4661 - d2_loss: 0.6096 - g_loss: 1.0964 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 12/15\n",
            "5/5 [==============================] - 2s 457ms/step - d1_loss: 0.4594 - d2_loss: 0.5704 - g_loss: 1.0811 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 13/15\n",
            "5/5 [==============================] - 2s 454ms/step - d1_loss: 0.4960 - d2_loss: 0.6170 - g_loss: 1.1739 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 14/15\n",
            "5/5 [==============================] - 2s 462ms/step - d1_loss: 0.5134 - d2_loss: 0.5712 - g_loss: 1.0527 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n",
            "Epoch 15/15\n",
            "5/5 [==============================] - 2s 465ms/step - d1_loss: 0.4998 - d2_loss: 0.6014 - g_loss: 0.9849 - d1_acc: 0.0000e+00 - d2_acc: 0.0000e+00 - g_acc: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Prepared (10, 32, 32, 3) (10, 32, 32, 3)\n",
            "Scaled (10, 299, 299, 3) (10, 299, 299, 3)\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "FID (same): [-2.2849644154288375e-05, -2.8657292987432977e-05, -3.398382927683108e-05]\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "FID (different): [42.51583625236779, 43.150280014234056, 44.81987750682479]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyplot.figure(figsize=(10,5))\n",
        "pyplot.title(\"FID \")\n",
        "pyplot.plot(fid_diff,label=\"FID_DIFF\")\n",
        "pyplot.xlabel(\"iterations\")\n",
        "pyplot.ylabel(\"FID\")\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "-mBzmuUZlo6z",
        "outputId": "618a60a6-cd88-4a97-a0d2-cec2e237069c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BpOnfIytnSU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB6LbrXwSyer",
        "outputId": "b60035d8-5e42-4dc5-caa1-4394c804ddd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared (10, 32, 32, 3) (10, 32, 32, 3)\n",
            "Scaled (10, 299, 299, 3) (10, 299, 299, 3)\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "FID (same): -0.000\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "FID (different): 37.938\n"
          ]
        }
      ],
      "source": [
        "# example of calculating the frechet inception distance in Keras\n",
        "import numpy\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets.mnist import load_data\n",
        "from skimage.transform import resize\n",
        "\n",
        "fake_image_path = glob(\"/content/drive/MyDrive/sample_images_drive/*\") \n",
        "# scale an array of images to a new size\n",
        "def scale_images(fake_image_path, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in fake_image_path:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)\n",
        " \n",
        "# calculate frechet inception distance\n",
        "def calculate_fid(model, images1, images2):\n",
        "\t# calculate activations\n",
        "\tact1 = model.predict(images1)\n",
        "\tact2 = model.predict(images2)\n",
        "\t# calculate mean and covariance statistics\n",
        "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "\t# calculate sum squared difference between means\n",
        "\tssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
        "\t# calculate sqrt of product between cov\n",
        "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
        "\t# check and correct imaginary numbers from sqrt\n",
        "\tif iscomplexobj(covmean):\n",
        "\t\tcovmean = covmean.real\n",
        "\t# calculate score\n",
        "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "\treturn fid\n",
        " \n",
        "# prepare the inception v3 model\n",
        "model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
        "# define two fake collections of images\n",
        "images1 = randint(0, 255, 10*32*32*3)\n",
        "images1 = images1.reshape((10,32,32,3))\n",
        "images2 = randint(0, 255, 10*32*32*3)\n",
        "images2 = images2.reshape((10,32,32,3))\n",
        "print('Prepared', images1.shape, images2.shape)\n",
        "# convert integer to floating point values\n",
        "images1 = images1.astype('float32')\n",
        "images2 = images2.astype('float32')\n",
        "# resize images\n",
        "images1 = scale_images(images1, (299,299,3))\n",
        "images2 = scale_images(images2, (299,299,3))\n",
        "print('Scaled', images1.shape, images2.shape)\n",
        "# pre-process images\n",
        "images1 = preprocess_input(images1)\n",
        "images2 = preprocess_input(images2)\n",
        "# fid between images1 and images1\n",
        "fid = calculate_fid(model, images1, images1)\n",
        "print('FID (same): %.3f' % fid)\n",
        "# fid between images1 and images2\n",
        "fid = calculate_fid(model, images1, images2)\n",
        "print('FID (different): %.3f' % fid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "UOdbjcusXLc9",
        "outputId": "a759f1fa-c009-4055-daf0-2b8e977c71e3"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-eb00b24d1559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generator and Discriminator Loss During Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"G\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md1_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"D1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md2_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"D2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'g_loss'"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pyplot.figure(figsize=(10,5))\n",
        "pyplot.title(\"Generator and Discriminator Loss During Training\")\n",
        "pyplot.plot(gan.train_step.g_loss,label=\"G\")\n",
        "pyplot.plot(gan.train_step.d1_loss,label=\"D1\")\n",
        "pyplot.plot(gan.train_step.d2_loss,label=\"D2\")\n",
        "pyplot.xlabel(\"iterations\")\n",
        "pyplot.ylabel(\"Loss\")\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpPfwN7SNlet"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sRskT_mNmD7"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}